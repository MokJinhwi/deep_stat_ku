{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100\n",
        "\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(N,1) # Unif(0,1)에서 난수 추출\n",
        "epsilon = (0.1 * np.random.randn(N, 1)) # N(0,1)에서 난수 추출\n",
        "y = true_b + true_w * x + epsilon # * 대신 @ 쓰면 행렬곱\n",
        "\n",
        "\n",
        "\n",
        "# Shuffles the indices\n",
        "idx = np.arange(N) # index를 만드는 코드\n",
        "split_index = int(N * 0.8) # train-validation split\n",
        "\n",
        "train_idx = idx[:split_index]\n",
        "val_idx = idx[split_index:]\n",
        "\n",
        "\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "1ZWAmdzk5FHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "def timer(func) :\n",
        "  def wrapper(*args, **kwargs) :\n",
        "    start_time = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "    computation_time = end_time - start_time\n",
        "    print(f\"Execution time of {func.__name__} : {computation_time} seconds\")\n",
        "    return result\n",
        "  return wrapper\n",
        "\n",
        "\n",
        "@timer\n",
        "def train_model_numpy(lr = 0.1, epochs = 1000) : # epochs : 몇 번 GD를 돌릴 것이냐냐\n",
        "  # Initialize parameters\n",
        "  b = np.random.randn(1)\n",
        "  w = np.random.randn(1)\n",
        "\n",
        "  for epoch in range(epochs) :\n",
        "    # Loss Computation\n",
        "    y_hat = b + w * x_train #b_hat, w_hat\n",
        "    error = y_hat - y_train\n",
        "    mse_loss = np.mean(error ** 2)\n",
        "\n",
        "    # Gradient Computation\n",
        "    b_grad = 2 * np.mean(error)\n",
        "    w_grad = 2 * np.mean(x_train * error) # 미분 유도해서 나온 식\n",
        "    b = b - lr * b_grad\n",
        "    w = w - lr * w_grad\n",
        "\n",
        "  return b, w"
      ],
      "metadata": {
        "id": "tQZGG8Ho4xpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_hat, w_hat = train_model_numpy()\n",
        "print(\"b_estimate:{}, w_estimate: {}\". format(b_hat, w_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ksz6QeS46j6",
        "outputId": "6752d2ed-f8c3-45b6-fc4a-aeb9b0a7cdb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of train_model_numpy : 0.030369997024536133 seconds\n",
            "b_estimate:[1.0234136], w_estimate: [1.93680757]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch\n"
      ],
      "metadata": {
        "id": "O_SNdwlj6fsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# create tensor at CPU\n",
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "y_train_tensor = torch.as_tensor(y_train)\n",
        "\n",
        "# create tensor at GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)"
      ],
      "metadata": {
        "id": "KBdstPbm6iXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # inplace 연산 쓰면 메모리 효율성이 높아진다 ~ 메모리 주소값을 거기다가 update\n",
        "\n",
        "def train_model_torch(lr=0.1, epochs=1000):\n",
        "    # Initialize parameters\n",
        "    ## requires_grad : pytorch와 numpy와 다른 점 (직접 미분계산 x), b와w는 학습대상이에요~라고 지정해주는 것\n",
        "    ## dtype : 자료의 형태를 지정, float double int 등등\n",
        "    ## device : CPU면 CPU에 올려라, GPU면 GPU에 올려라\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Loss computation\n",
        "        # 모델 연산부분은 똑같음\n",
        "        y_hat = b + w * x_train_tensor\n",
        "        error = (y_hat - y_train_tensor)\n",
        "        mse_loss = torch.mean(error ** 2)\n",
        "\n",
        "        # Gradient computation and descent\n",
        "        # 차이발생\n",
        "        mse_loss.backward() # 미분 알아서 계산해줌, gradient 계산은 해주는데 update는 안해줌\n",
        "        with torch.no_grad(): # no_grad : autograd 기능을 잠시 멈춤 -> 안하면 컴퓨터 멈춘다\n",
        "            b -= lr * b.grad # update 구현해줘야함\n",
        "            w -= lr * w.grad\n",
        "        b.grad.zero_() #\"_\" inplace operation을 쓰라는 기호, gradient 0으로 초기화\n",
        "        w.grad.zero_()\n",
        "    return b, w"
      ],
      "metadata": {
        "id": "vFkgq5gu8XvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_hat, w_hat = train_model_torch()\n",
        "print(\"b_estimate:{}, w_estimate: {}\". format(b_hat, w_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mst_8IubBcea",
        "outputId": "3c637444-55e2-4834-8705-f4286de3ba5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b_estimate:tensor([1.0234], requires_grad=True), w_estimate: tensor([1.9368], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch advance"
      ],
      "metadata": {
        "id": "CgaDoNJvBqiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "def train_model_torch(lr=0.1, epochs=1000):\n",
        "    # Initialize parameters\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "    parameters = [b,w]\n",
        "    optimizer = optim.SGD(parameters, lr=lr) ## learning rate 넣어주기\n",
        "    mse_loss = nn.MSELoss() ## Loss를 바꾸려면 갈아끼면된다.\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Loss computation\n",
        "        y_hat = b + w * x_train_tensor\n",
        "        loss = mse_loss(y_hat, y_train_tensor)\n",
        "        # Gradient computation and descent\n",
        "        loss.backward() # 미분 알아서 계산해줌, gradient 계산은 해주는데 update는 안해줌\n",
        "        optimizer.step() # 위의 with 문\n",
        "        optimizer.zero_grad() # gradient 0으로 초기화, parameter 개수가 바뀌어도 상관없음\n",
        "    return b, w"
      ],
      "metadata": {
        "id": "OP6rXeaIBoQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_hat, w_hat = train_model_torch()\n",
        "print(\"b_estimate:{}, w_estimate: {}\". format(b_hat, w_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO5VEnCNDEgl",
        "outputId": "d0fdabcf-4464-4674-ce62-9cafba121932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b_estimate:tensor([1.0234], requires_grad=True), w_estimate: tensor([1.9368], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}